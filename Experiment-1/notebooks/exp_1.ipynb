{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzvGyXiytQ54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet-ml in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (2.0.5)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (1.0.3)\n",
      "Requirement already satisfied: netifaces>=0.10.7 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (0.10.9)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (7.352.0)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (1.0.2)\n",
      "Requirement already satisfied: six in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (1.12.0)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (3.0.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (2.22.0)\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (0.56.0)\n",
      "Requirement already satisfied: comet-git-pure>=0.19.11 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from comet-ml) (0.19.11)\n",
      "Requirement already satisfied: configobj; extra == \"ini\" in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet-ml) (5.0.6)\n",
      "Requirement already satisfied: setuptools in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from jsonschema>=2.6.0->comet-ml) (41.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from jsonschema>=2.6.0->comet-ml) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from jsonschema>=2.6.0->comet-ml) (0.15.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from requests>=2.18.4->comet-ml) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from requests>=2.18.4->comet-ml) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from requests>=2.18.4->comet-ml) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/dudeperf3ct/.virtualenvs/dl/lib/python3.6/site-packages (from requests>=2.18.4->comet-ml) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mowmIGaKxPcO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TextRecognizer'...\n",
      "remote: Enumerating objects: 229, done.\u001b[K\n",
      "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
      "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
      "remote: Total 229 (delta 125), reused 209 (delta 107), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (229/229), 21.26 MiB | 1.56 MiB/s, done.\n",
      "Resolving deltas: 100% (125/125), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/dudeperf3ct/TextRecognizer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZBaKb-7bxSGt",
    "outputId": "c4b9000f-b820-48cf-995f-e367db0da2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dudeperf3ct/Downloads/TextRecognizer/Experiment-1/notebooks/TextRecognizer/Experiment-1/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd TextRecognizer/Experiment-1/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Qu7ekkktcIE"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GEuepLnv0S-X",
    "outputId": "736fd7a5-ad48-40ef-c7a7-e6356a4ed528"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYaGiND_xZgS"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MG7-Bqh-xkq9"
   },
   "outputs": [],
   "source": [
    "from src.data.emnist_dataset import EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "zm-AKFNFxoOj",
    "outputId": "b4082d2e-108c-44f6-e4f7-81d3908f696d"
   },
   "outputs": [],
   "source": [
    "dataset = EMNIST()\n",
    "(x_train, y_train), (x_test, y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "f43fcv-XzNkS",
    "outputId": "d2a7aa46-72b0-491a-bd94-4fbdfc76366b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST Dataset\n",
      "Num classes: 62\n",
      "Mapping: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z'}\n",
      "Input shape: [28, 28]\n",
      "\n",
      "Training shape: (697932, 28, 28) (697932, 62)\n",
      "Test shape: (116323, 28, 28) (116323, 62)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print('Training shape:', x_train.shape, y_train.shape)\n",
    "print('Test shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovr_B78ds-st"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8RKzcaQs-SC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAJmzs30s9eT"
   },
   "outputs": [],
   "source": [
    "%%writefile ../src/training/train_model.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from comet_ml import Experiment\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(__file__).resolve().parents[2]))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.training.util import train_model\n",
    "from src.data.emnist_dataset import EMNIST\n",
    "from src.models.character_model import Character_Model\n",
    "from src.networks.lenet import lenet\n",
    "import argparse\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\", \"--save-model\", type=int, default=False,\n",
    "        help=\"whether or not model should be saved\")\n",
    "    parser.add_argument(\"-w\", \"--weights\", type=str, default=True,\n",
    "        help=\"whether or not weights should be saved\")\n",
    "    parser.add_argument(\"-m\", '--model', type=str, default=\"Character_Model\",\n",
    "        help=\"which model to use\")\n",
    "    parser.add_argument(\"-n\", '--network', type=str, default=\"lenet\",\n",
    "        help=\"which network architecture to use\")\n",
    "    parser.add_argument(\"-d\", '--dataset', type=str, default=\"EMNIST\",\n",
    "        help=\"which dataset to use\")\n",
    "    parser.add_argument(\"-e\", '--epochs', type=int, default=10,\n",
    "        help=\"Number of epochs\")\n",
    "    parser.add_argument(\"-b\", '--batch_size', type=int, default=32,\n",
    "        help=\"Batch size\")        \n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "funcs = {'EMNIST': EMNIST, 'lenet': lenet, 'Character_Model': Character_Model}\n",
    "\n",
    "\n",
    "def train(args, use_comet : bool = True):\n",
    "\n",
    "    data_cls = funcs[args['dataset']]\n",
    "    model_cls = funcs[args['model']]\n",
    "    network = funcs[args['network']]\n",
    "\n",
    "    print ('[INFO] Getting dataset...')\n",
    "    data = data_cls()\n",
    "    (x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "    \n",
    "    #Used for testing only\n",
    "    x_train = x_train[:100, :, :]\n",
    "    y_train = y_train[:100, :]\n",
    "    x_test = x_test[:100, :, :]\n",
    "    y_test = y_test[:100, :]\n",
    "    print ('[INFO] Training shape: ', x_train.shape, y_train.shape)\n",
    "    print ('[INFO] Test shape: ', x_test.shape, y_test.shape)\n",
    "    #delete these lines\n",
    "\n",
    "    # add this stratify=y_train after verifying distribution of classes \n",
    "    (x_train, x_valid, y_train, y_valid) = train_test_split(x_train, y_train, test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "\n",
    "    print ('[INFO] Training shape: ', x_train.shape, y_train.shape)\n",
    "    print ('[INFO] Validation shape: ', x_valid.shape, y_valid.shape)\n",
    "    print ('[INFO] Test shape: ', x_test.shape, y_test.shape)\n",
    "\n",
    "    print ('[INFO] Setting up the model..')\n",
    "    model = model_cls(network, data_cls)\n",
    "    print (model)\n",
    "    \n",
    "    dataset = dict({\n",
    "        'x_train' : x_train,\n",
    "        'y_train' : y_train,\n",
    "        'x_valid' : x_valid,\n",
    "        'y_valid' : y_valid,\n",
    "        'x_test' : x_test,\n",
    "        'y_test' : y_test\n",
    "    })\n",
    "\n",
    "    if use_comet:\n",
    "        #create an experiment with your api key\n",
    "        experiment = Experiment(api_key='WVBNRAfMLCBWslJAAsffxM4Gz',\n",
    "                                project_name='emnist',\n",
    "                                auto_param_logging=False)\n",
    "        \n",
    "        print ('[INFO] Starting Training...')\n",
    "        #will log metrics with the prefix 'train_'   \n",
    "        with experiment.train():\n",
    "            _ = train_model(\n",
    "                    model,\n",
    "                    dataset,\n",
    "                    batch_size=args['batch_size'],\n",
    "                    epochs=args['epochs']\n",
    "                    )\n",
    "\n",
    "        print ('[INFO] Starting Testing...')    \n",
    "        #will log metrics with the prefix 'test_'\n",
    "        with experiment.test():  \n",
    "            loss, score = model.evaluate(dataset, args['batch_size'])\n",
    "            print(f'[INFO] Test evaluation: {score}')\n",
    "            metrics = {\n",
    "                'loss':loss,\n",
    "                'accuracy':score\n",
    "            }\n",
    "            experiment.log_metrics(metrics)    \n",
    "\n",
    "        experiment.log_parameters(args)\n",
    "        experiment.log_dataset_hash(x_train) #creates and logs a hash of your data \n",
    "\n",
    "    else :\n",
    "\n",
    "        print ('[INFO] Starting Training...')\n",
    "        train_model(\n",
    "            model,\n",
    "            dataset,\n",
    "            batch_size=args['batch_size'],\n",
    "            epochs=args['epochs']\n",
    "            )\n",
    "        print ('[INFO] Starting Testing...')    \n",
    "        loss, score = model.evaluate(dataset, args['batch_size'])\n",
    "        print(f'[INFO] Test evaluation: {score}')\n",
    "\n",
    "    if args['weights']:\n",
    "        model.save_weights()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run experiment.\"\"\"\n",
    "    args = _parse_args()\n",
    "    train(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2LQHKpHs_5i"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3MJMFJbbze7S",
    "outputId": "a256d626-a164-433b-ed0f-76906e88eacd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Getting dataset...\n"
     ]
    }
   ],
   "source": [
    "! python ../src/training/train_model.py -b 16 -e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJZX0yAQBgjx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8An2rDQwtBT5"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2v7DlsltCC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnbo0dSHtCWd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNK0MNnjtCb7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "exp-1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
